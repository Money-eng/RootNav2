model:
    arch: HG
data:
    dataset: roots
    path: ./OSR_Root_dataset/ #edit your dataset path
training:
    train_iters: 25000000
    batch_size: 6   # (for two GPUs) chnage according to your GPU 
    val_interval: 500
    n_workers: 6    # (for two GPUs) chnage according to your GPU
    print_interval: 10
    optimizer:
        name: 'rmsprop'
        lr: 0.0001   
        weight_decay: 0.001
        momentum: 0.9
    loss:
        name: 'cross_entropy'
        size_average: False
    # Augmentations Configuration
    augmentations:
        hflip: 0.5

    lr_schedule:
    resume:                                              #./inference/models/wheat_bluepaper.pth
                                                         # (can use the trained model from inference section)
